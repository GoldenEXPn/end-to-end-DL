{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T06:06:51.579233Z",
     "start_time": "2024-11-12T06:06:48.681401Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "from Model_calibration_dataset import get_cifar10_classes\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T06:07:04.788615Z",
     "start_time": "2024-11-12T06:06:51.582238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve datasets and dataloaders\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_dataset, val_dataset, test_data = get_cifar10_classes(transform_train, transform_test)\n",
    "\n",
    "# Create dataloader\n",
    "batch_size=128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "3f0848c33abe58e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T06:07:04.874743Z",
     "start_time": "2024-11-12T06:07:04.868704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Common functions\n",
    "class LabelSmoothingBCE(nn.Module):  # CrossEntropyLoss has label smoothing, BCE does not\n",
    "    def __init__(self, smoothing=1.0):\n",
    "        super(LabelSmoothingBCE, self).__init__()\n",
    "        assert 0.0 <= smoothing < 1.0\n",
    "        self.smoothing = smoothing\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        with torch.no_grad():\n",
    "            target = target * (1 - self.smoothing) + (self.smoothing / 2)\n",
    "        return self.loss_fn(logits, target)\n",
    "    \n",
    "\n",
    "def finetune_model(model, lr, train_loader, smoothing, num_epoch=10):\n",
    "    model.to(device)\n",
    "    criterion = LabelSmoothingBCE(smoothing)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epoch}, Loss: {epoch_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_calibration(model, test_loader, label=''):\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            all_probs.extend(outputs)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "    # Plot reliability curve\n",
    "    prob_true, prob_pred = calibration_curve(all_labels, all_probs, n_bins=10)\n",
    "    return prob_true, prob_pred, all_probs, all_labels"
   ],
   "id": "b819221233477be3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T06:29:22.102297Z",
     "start_time": "2024-11-12T06:26:34.513296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finetune with label smoothing and evaluate calibration \n",
    "smoothing_values = [0.0, 0.1, 0.2, 0.3]\n",
    "for alpha in smoothing_values:\n",
    "    print(f'Finetuning with alpha value: {alpha}')\n",
    "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1)  # binary classification\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    results = {}\n",
    "    model = finetune_model(model, 1e-3, train_loader, alpha)\n",
    "    label = f'Alpha: {alpha}'\n",
    "    prob_true, prob_pred, all_probs, all_labels = evaluate_calibration(model, test_loader, label)\n",
    "    results[int(alpha * 10)] = {\n",
    "        'prob_true': prob_true,\n",
    "        'prob_pred': prob_pred,\n",
    "        'all_probs': all_probs,\n",
    "        'all_labels': all_labels\n",
    "    }"
   ],
   "id": "8e71673130146c93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning with alpha value: 0.0\n",
      "Epoch 1/10, Loss: 0.7114\n",
      "Epoch 2/10, Loss: 0.6402\n",
      "Epoch 3/10, Loss: 0.6072\n",
      "Epoch 4/10, Loss: 0.5882\n",
      "Epoch 5/10, Loss: 0.5699\n",
      "Epoch 6/10, Loss: 0.5524\n",
      "Epoch 7/10, Loss: 0.5369\n",
      "Epoch 8/10, Loss: 0.5245\n",
      "Epoch 9/10, Loss: 0.5059\n",
      "Epoch 10/10, Loss: 0.4951\n",
      "Finetuning with alpha value: 0.1\n",
      "Epoch 1/10, Loss: 0.7043\n",
      "Epoch 2/10, Loss: 0.6601\n",
      "Epoch 3/10, Loss: 0.6336\n",
      "Epoch 4/10, Loss: 0.6199\n",
      "Epoch 5/10, Loss: 0.6032\n",
      "Epoch 6/10, Loss: 0.5922\n",
      "Epoch 7/10, Loss: 0.5815\n",
      "Epoch 8/10, Loss: 0.5737\n",
      "Epoch 9/10, Loss: 0.5593\n",
      "Epoch 10/10, Loss: 0.5492\n",
      "Finetuning with alpha value: 0.2\n",
      "Epoch 1/10, Loss: 0.7300\n",
      "Epoch 2/10, Loss: 0.6807\n",
      "Epoch 3/10, Loss: 0.6578\n",
      "Epoch 4/10, Loss: 0.6434\n",
      "Epoch 5/10, Loss: 0.6330\n",
      "Epoch 6/10, Loss: 0.6232\n",
      "Epoch 7/10, Loss: 0.6157\n",
      "Epoch 8/10, Loss: 0.6084\n",
      "Epoch 9/10, Loss: 0.6024\n",
      "Epoch 10/10, Loss: 0.5963\n",
      "Finetuning with alpha value: 0.3\n",
      "Epoch 1/10, Loss: 0.7223\n",
      "Epoch 2/10, Loss: 0.6883\n",
      "Epoch 3/10, Loss: 0.6716\n",
      "Epoch 4/10, Loss: 0.6600\n",
      "Epoch 5/10, Loss: 0.6524\n",
      "Epoch 6/10, Loss: 0.6467\n",
      "Epoch 7/10, Loss: 0.6411\n",
      "Epoch 8/10, Loss: 0.6334\n",
      "Epoch 9/10, Loss: 0.6315\n",
      "Epoch 10/10, Loss: 0.6246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T06:30:32.178947Z",
     "start_time": "2024-11-12T06:30:32.164926Z"
    }
   },
   "cell_type": "code",
   "source": "results[int(1)]",
   "id": "53d914fc88ca3c02",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results[\u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1\u001B[39m)]\n",
      "\u001B[1;31mKeyError\u001B[0m: 1"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T06:30:25.992835Z",
     "start_time": "2024-11-12T06:30:25.974270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for alpha in smoothing_values:\n",
    "    prob_true = results[alpha*10]['prob_true']\n",
    "    prob_pred = results[alpha*10]['prob_pred']\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label=f'Label Smoothing: {alpha}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='black')  # Draw diagonal\n",
    "plt.title('Reliability with label smoothing')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "17b9200e2266da88",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m alpha \u001B[38;5;129;01min\u001B[39;00m smoothing_values:\n\u001B[1;32m----> 4\u001B[0m     prob_true \u001B[38;5;241m=\u001B[39m results[alpha\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m10\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprob_true\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m     prob_pred \u001B[38;5;241m=\u001B[39m results[alpha\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m10\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprob_pred\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      6\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(prob_pred, prob_true, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mo\u001B[39m\u001B[38;5;124m'\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLabel Smoothing: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00malpha\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 0.0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train from scratch with label smoothing\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)  # binary classification\n"
   ],
   "id": "6bfff421c471c29b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Apply platt scaling on models from previous two parts and the one from part 1",
   "id": "3092dc1726adf315",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
